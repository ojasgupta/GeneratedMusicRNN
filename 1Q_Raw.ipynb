{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GT 640M LE (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "charToInt = {}\n",
    "intToChar = {}\n",
    "def getEncoding(merged_data):\n",
    "    indx = 0\n",
    "    fin = []\n",
    "    for x in merged_data:\n",
    "        if x not in charToInt:\n",
    "            charToInt[x] = indx\n",
    "            intToChar[indx] = x\n",
    "            indx += 1\n",
    "        fin.append(charToInt[x])\n",
    "    return fin\n",
    "            \n",
    "def loadMusic(file):\n",
    "    f = open(file, 'r')\n",
    "    text = f.read()\n",
    "    text = text.replace(\"\\r\", \"\")\n",
    "    words = re.split(r\"(\\s+)\", text)\n",
    "    new_words = words #[x for x in words if (x != '<start>' and x != '<end>')] # get rid of <start> and <end>\n",
    "    data = []\n",
    "    [data.append(list(w)) for w in new_words]\n",
    "    merged_data = np.asarray(list(itertools.chain.from_iterable(data)))  \n",
    "#    s = set(merged_data)\n",
    "#    char_int = [ch:i for i,ch in enumerate(s)] # encode characters to integers\n",
    "#    int_char = [i:ch for i,ch in enumerate(s)] # encode integers to characters\n",
    "    encoded_data = getEncoding(merged_data)#[ord(x) for x in merged_data] # assing ascii labels to characters\n",
    "    return encoded_data\n",
    "\n",
    "def prepareData(data, t):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(data) - t - 1):\n",
    "\t\ta = data[i:(i+t)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(data[i + t])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "def splitData(data, v):\n",
    "    train_size = int(len(data[0]) * v) # v is between 0 and 1\n",
    "    train, test = (data[0][0:train_size],data[1][0:train_size]), (data[0][train_size:len(data[0])],data[1][train_size:len(data[0])])\n",
    "    return train, test\n",
    "\n",
    "def sliceData(data, s):\n",
    "    dataX, dataY = data[0], data[1]\n",
    "    X, Y = [], []\n",
    "    windowStride = 5\n",
    "    for i in range((len(data[0])-s - 1) / windowStride):\n",
    "        seq = i * windowStride #randint(1,len(data[0])-20)\n",
    "        sliceX = dataX[seq:seq+s]\n",
    "        sliceY = dataY[seq+s-1]\n",
    "        X.append(sliceX)\n",
    "        Y.append(sliceY)\n",
    "    data = (X, Y)\n",
    "    return splitData(data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "80229 80229\n",
      "(2406870, 93) (80229, 93) (601740, 93) (20058, 93)\n",
      "(2406870, 93) (80229, 93) (601740, 93) (20058, 93)\n"
     ]
    }
   ],
   "source": [
    "file = 'input.txt'\n",
    "abc_list = loadMusic(file) # read in data\n",
    "lvl = np.min(abc_list)\n",
    "abc_list = abc_list - lvl\n",
    "vocab = np.max(abc_list)\n",
    "print lvl\n",
    "\n",
    "\n",
    "data = prepareData(abc_list, 1) # prepare inputs and targets\n",
    "#dataslice = sliceData(data, s = 2) # slice into sequences of length s\n",
    "\n",
    "train_seq, test_seq = sliceData(data, 30)\n",
    "y_train = train_seq[1]\n",
    "y_test = test_seq[1]\n",
    "\n",
    "print len(y_train), len(train_seq[0])\n",
    "\n",
    "# one-hot encoding targets\n",
    "X_train = np_utils.to_categorical(train_seq[0], vocab+1)\n",
    "X_test = np_utils.to_categorical(test_seq[0], vocab+1)\n",
    "Y_train = np_utils.to_categorical(train_seq[1], vocab+1)\n",
    "Y_test = np_utils.to_categorical(test_seq[1], vocab+1)\n",
    "print X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "\n",
    "seq = 30; # sequence length\n",
    "X_train = X_train[0:int(X_train.shape[0]/seq)*seq][:]\n",
    "Y_train = Y_train[0:int(Y_train.shape[0])][:]\n",
    "X_test = X_test[0:int(X_test.shape[0]/seq)*seq][:]\n",
    "Y_test = Y_test[0:int(Y_test.shape[0])][:]\n",
    "print X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "\n",
    "X_train = X_train.reshape(int(X_train.shape[0]/seq), seq, X_train.shape[1]) # reshape input for RNN\n",
    "X_test = X_test.reshape(int(X_test.shape[0]/seq), seq, X_test.shape[1])\n",
    "Y_train = Y_train.reshape(int(Y_train.shape[0]), Y_train.shape[1]) # reshape input for RNN\n",
    "Y_test = Y_test.reshape(int(Y_test.shape[0]), Y_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80229, 30, 93) (80229, 93) (20058, 30, 93) (20058, 93)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for x in X_train[0]:\n",
    "#     print (intToChar[np.argmax(x)])\n",
    "# print np.argmax(Y_train[0])\n",
    "# print (intToChar[np.argmax(Y_train[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "simplernn_2 (SimpleRNN)          (None, 150)           36600       simplernn_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 93)            14043       simplernn_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 93)            0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 50,643\n",
      "Trainable params: 50,643\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hid_neurons = 150\n",
    "nb_classes = np.shape(Y_train)[-1]\n",
    "\n",
    "\n",
    "#%% create model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(output_dim = hid_neurons,\n",
    "                    init='glorot_uniform', inner_init='orthogonal', activation='relu',\n",
    "                    W_regularizer=None, U_regularizer=None, b_regularizer=None,\n",
    "                    dropout_W=0.0, dropout_U=0.0, return_sequences = False,\n",
    "                    input_shape = X_train.shape[1:]))\n",
    "model.add(Dense(output_dim = nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "adam_op = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam_op,\n",
    "              metrics=['accuracy'])\n",
    "#%% train model and save weights\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80229/80229 [==============================] - 43s - loss: 1.2506 - acc: 0.6122    \n",
      "Epoch 2/10\n",
      "80229/80229 [==============================] - 44s - loss: 1.2436 - acc: 0.6140    \n",
      "Epoch 3/10\n",
      "80229/80229 [==============================] - 43s - loss: 1.2358 - acc: 0.6163    \n",
      "Epoch 4/10\n",
      "80229/80229 [==============================] - 38s - loss: 1.2294 - acc: 0.6193    \n",
      "Epoch 5/10\n",
      "80229/80229 [==============================] - 38s - loss: 1.2187 - acc: 0.6219    \n",
      "Epoch 6/10\n",
      "80229/80229 [==============================] - 38s - loss: 1.2110 - acc: 0.6227    \n",
      "Epoch 7/10\n",
      "80229/80229 [==============================] - 47s - loss: 1.2058 - acc: 0.6244    \n",
      "Epoch 8/10\n",
      "80229/80229 [==============================] - 38s - loss: 1.2000 - acc: 0.6257    \n",
      "Epoch 9/10\n",
      "80229/80229 [==============================] - 38s - loss: 1.1931 - acc: 0.6284    \n",
      "Epoch 10/10\n",
      "80229/80229 [==============================] - 37s - loss: 1.1855 - acc: 0.6300    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f985a7b7550>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":id:hn-hornpipe-19\n",
      "M:C|\n",
      "K:Deor\n",
      "AE ED|1 BA | B>c B>A | A/B/A/B/ cB cc|\n",
      "d3 g2e|gec B2B|dcd ead|ede cAG|AF ED||\n",
      "GG FA|d2 AB|ef ed|:|\n",
      "<end>\n",
      "<start>\n",
      "X:10\n",
      "T:Jamisre Gous cone va-phie\n",
      ".D.C.\n",
      "W:Lis Cooteur de la nan\n",
      "Z:id:hn-mazurka-9\n",
      "M:C|\n",
      "K:D\n",
      "Bdec =AADE | GFGE D2FA:|\n",
      "B2GB GFED |: B2z z2z | E>E D>D | BB B>B | BA/B/ B/d/d/e/ G2B|c2B c3 :|\n",
      "<end>\n",
      "<start>\n",
      "X:20\n",
      "T:Lee Montin: Ia (one la Danellen\n",
      "R:jig\n",
      "H:See arcone Raet fu-me la de Gerbim?n Mors and Minny, #120157Ie |\n",
      "c2c2 :|\n",
      "<end>\n",
      "<start>\n",
      "X:89\n",
      "T:Maring\n",
      "T:h'u Maggie\n",
      "R:Carolan\n",
      "R:air\n",
      "H:Tram.id hois bet Inam Auran.\n",
      "H:Thartis bon 1\n",
      "Z:Daven-c'a ca\n",
      "W:ankon: Matc on-tr?mn Hon\n",
      "O:France\n",
      "A:Provence\n",
      "C:?m\n",
      "R:Maz2\n",
      "O:\n",
      "D/2\n",
      "R:cerolay's\n",
      "T:An pardion Gincont ReNtent wettete tEemine, The\n",
      "T:Dant'ranae\n",
      "H:Raelaul te jeandons on the Fithereite:transe\n",
      "D:Morled le Gedyry Gurvi?\n",
      "O:France\n",
      "A:Chrnain\n",
      "C:Trad.\n",
      "<end>\n",
      "Z:Pant\n",
      "O:France\n",
      "R:garigtice\n",
      "H:The nou the Denais, The\n",
      "T:Varcels\n",
      "R:Plorigis\n",
      "R:Mancendmoh\n",
      "D:Faria triginaid tamin: Thee Huph Morlose, Tor\n",
      "R:polka\n",
      "Z:in:hu-marcheadgan'rok, The\n",
      "T:Callerid\n",
      "Z:id:hn-polka-13\n",
      "M:2/4\n",
      "L:1/16\n",
      "K:C\n",
      "BG |:\n",
      "B2BG cBcd | dfbgag f2:|\n",
      "w:Od tie (1984)\n",
      "Z:Transcrit et/ou corrig? par Michel BELLON - 2005-03-06\n",
      "Z:Pour toute observation mailto:galouvielle@free.fr\n",
      "M:6/8\n",
      "Q:1/4=163\n",
      "Z:Transcrit et/ou corrig? par Michel BELLON - 2007-08-06\n",
      "Z:Pour toute observation"
     ]
    }
   ],
   "source": [
    "inp = X_train[0, :, :]\n",
    "inp.shape\n",
    "import sys\n",
    "\n",
    "def printInp(inp):\n",
    "    print \"================================\"\n",
    "    for x in inp:\n",
    "        print intToChar[np.argmax(x)],\n",
    "    print \"\\n++================================\"\n",
    "\n",
    "for i in range(1300):\n",
    "    out = model.predict(np.reshape(inp, (1, 30, 93)))\n",
    "    final = np.random.choice(np.arange(0, 93), p = out[0])\n",
    "    sys.stdout.write(intToChar[final])\n",
    "    nextInp = np_utils.to_categorical(final, nb_classes=93)\n",
    "    inp = np.ma.row_stack((inp, nextInp))\n",
    "    inp = inp[1:]\n",
    "#     printInp(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "#plt.title('model loss for %d samples per category')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "#plt.title('model accuracy for %d samples per category' % samCat)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "#%% load weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-19-1.9435.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "#%% generating music\n",
    "\n",
    "seed = X_train[1]\n",
    "pattern = seed\n",
    "for i in range(0,1000):\n",
    "    \tx = np.reshape(pattern, (1, pattern.shape[0], pattern.shape[1]))\n",
    "    \tprediction = model.predict(x, verbose=1)\n",
    "     \tfinal = np.random.choice(np.arange(0, 256), p = prediction)\n",
    "        print intToChar[final]\n",
    "        \n",
    "      \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
